import streamlit as st
import requests
from bs4 import BeautifulSoup
import re
import random

st.set_page_config(page_title="ãƒãƒ­ãƒ¼ãƒ¯ãƒ¼ã‚¯æ±‚äººæŠ½å‡ºãƒ„ãƒ¼ãƒ«", layout="wide")
st.title("ğŸ“‹ ãƒãƒ­ãƒ¼ãƒ¯ãƒ¼ã‚¯æ±‚äººæŠ½å‡ºãƒ„ãƒ¼ãƒ«")
st.markdown("URLã‚’1è¡Œãšã¤è²¼ã‚Šä»˜ã‘ã¦ãã ã•ã„ã€‚æ±‚äººæƒ…å ±ã‚’æŠ½å‡ºã—ã¦è¡¨ç¤ºã—ã¾ã™ã€‚")

with st.form("job_form"):
    urls_input = st.text_area("ğŸ”— æ±‚äººURLã‚’å…¥åŠ›", height=200)
    submitted = st.form_submit_button("â–¶ï¸ æƒ…å ±ã‚’æŠ½å‡º")

# æ±‚äººæ¦‚è¦ã®ç”Ÿæˆï¼ˆ100ã€œ200å­—ç›®å®‰ã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆï¼‰
def generate_summary(desc, salary_min, salary_max, loc, time, welfare, holiday, notes, job_title):
    desc_part = desc[:40] + "â€¦" if desc and len(desc) > 40 else desc

    benefit_keywords = []
    if any(kw in welfare + notes for kw in ["ç¤¾å®…", "ä½å®…æ‰‹å½“", "é€€è·é‡‘"]):
        benefit_keywords.append("å……å®Ÿã—ãŸç¦åˆ©åšç”Ÿ")
    if any(kw in welfare + notes for kw in ["è³‡æ ¼å–å¾—", "ç ”ä¿®", "ã‚­ãƒ£ãƒªã‚¢"]):
        benefit_keywords.append("ã‚¹ã‚­ãƒ«ã‚¢ãƒƒãƒ—æ”¯æ´ã‚ã‚Š")
    if any(kw in welfare + notes for kw in ["è‚²å…", "æ‰¶é¤Š", "å­è‚²ã¦"]):
        benefit_keywords.append("è‚²å…æ”¯æ´åˆ¶åº¦ã‚ã‚Š")
    if any(kw in welfare + notes + loc for kw in ["ãƒã‚¤ã‚«ãƒ¼", "è»Šé€šå‹¤", "é§è»Šå ´"]):
        benefit_keywords.append("ãƒã‚¤ã‚«ãƒ¼é€šå‹¤OK")
    if holiday:
        benefit_keywords.append(f"ä¼‘æ—¥ï¼š{holiday}")

    benefits_sentence = "ã€".join(benefit_keywords)

    if desc_part and salary_min and salary_max and loc and time:
        return f"{desc_part} çµ¦ä¸ã¯æœˆçµ¦{salary_min}ã€œ{salary_max}å††ã€å‹¤å‹™åœ°ã¯{loc}ã€å‹¤å‹™æ™‚é–“ã¯{time}ã§ã™ã€‚{benefits_sentence}ã€‚"
    elif loc:
        return f"å‹¤å‹™åœ°ã¯{loc}ã§ã™ã€‚è·å ´ç’°å¢ƒã‚„å¾…é‡ã«ã¤ã„ã¦ã¯ã€ãŠæ°—è»½ã«ãŠå•ã„åˆã‚ã›ãã ã•ã„ã€‚"
    else:
        base = job_title if job_title else "ãŠä»•äº‹"
        desc_fallback = desc[:40] + "â€¦" if desc and len(desc) > 40 else desc
        if desc_fallback:
            return f"{base}ã«é–¢ã™ã‚‹æ±‚äººã§ã™ã€‚ä¸»ãªå†…å®¹ã¯ã€Œ{desc_fallback}ã€ã§ã™ã€‚è©³ç´°æ¡ä»¶ã¯ãŠå•ã„åˆã‚ã›ãã ã•ã„ã€‚"
        else:
            return f"{base}ã«é–¢ã™ã‚‹æ±‚äººã§ã™ã€‚è©³ç´°æƒ…å ±ã¯ç¾åœ¨æº–å‚™ä¸­ã§ã™ãŒã€ã”èˆˆå‘³ã®ã‚ã‚‹æ–¹ã¯ãœã²ãŠæ°—è»½ã«ã”ç›¸è«‡ãã ã•ã„ã€‚"
    base = desc[:60] + "â€¦" if desc and len(desc) > 60 else desc
    parts = []
    if base:
        parts.append(base)
    if salary_min and salary_max:
        parts.append(f"çµ¦ä¸ã¯æœˆçµ¦{salary_min}ã€œ{salary_max}å††")
    if loc:
        parts.append(f"å‹¤å‹™åœ°ï¼š{loc}")
    if time:
        parts.append(f"å‹¤å‹™æ™‚é–“ï¼š{time}")
    return "ã€".join(parts) + "ã€‚"

# ãŠã™ã™ã‚ãƒã‚¤ãƒ³ãƒˆæŠ½å‡ºã®æ‹¡å¼µï¼ˆæœ€ä½3ä»¶ä¿è¨¼ï¼‰
def extract_recommendations(salary_min, welfare, notes, work_desc, location):
    recs = []
    try:
        if salary_min and int(salary_min) >= 250000:
            recs.append("é«˜çµ¦ä¸ï¼ˆæœˆçµ¦25ä¸‡å††ä»¥ä¸Šï¼‰")
    except ValueError:
        pass
    if "ãƒ¬ã‚¢" in work_desc or "ä¹…ã—ã¶ã‚Š" in work_desc:
        recs.append("å¸Œå°‘ãªãƒ¬ã‚¢æ±‚äºº")
    if any(kw in (welfare + notes) for kw in ["ç¤¾å®…", "è³‡æ ¼", "é€€è·é‡‘", "æ‰¶é¤Š", "ä½å®…"]):
        recs.append("ç¦åˆ©åšç”ŸãŒå……å®Ÿ")
    if any(kw in (work_desc + notes) for kw in ["å¤œå‹¤ãªã—", "æ®‹æ¥­ãªã—", "æ—¥å‹¤ã®ã¿"]):
        recs.append("åƒãã‚„ã™ã„å‹¤å‹™ä½“åˆ¶")
    if any(kw in (welfare + notes + location) for kw in ["é§…", "ãƒã‚¤ã‚«ãƒ¼", "è»Šé€šå‹¤", "ãƒã‚¹"]):
        recs.append("ã‚¢ã‚¯ã‚»ã‚¹è‰¯å¥½")

    # è£œå®Œå€™è£œï¼ˆå¸¸ã«3ã¤ã¯å‡ºã™ï¼‰
    fallback = ["ãƒ–ãƒ©ãƒ³ã‚¯OK", "ç ”ä¿®åˆ¶åº¦ã‚ã‚Š", "ãƒãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯é‡è¦–", "åœ°åŸŸå¯†ç€å‹", "ã‚·ãƒ•ãƒˆæŸ”è»Ÿå¯¾å¿œ"]
    while len(recs) < 3:
        extra = random.choice(fallback)
        if extra not in recs:
            recs.append(extra)
    return recs

if submitted:
    urls = [url.strip() for url in urls_input.split("\n") if url.strip()]
    if not urls:
        st.warning("URLã‚’1ä»¶ä»¥ä¸Šå…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    else:
        for i, url in enumerate(urls, 1):
            try:
                response = requests.get(url)
                response.encoding = response.apparent_encoding
                soup = BeautifulSoup(response.text, 'html.parser')

                def get_text(label):
                    elem = soup.find("th", string=label)
                    if elem and elem.find_next("td"):
                        return elem.find_next("td").get_text(strip=True)
                    return ""

                job_title = soup.find("h2").get_text(strip=True) if soup.find("h2") else ""
                company = get_text("äº‹æ¥­æ‰€å")
                work_desc = get_text("ä»•äº‹ã®å†…å®¹")
                location = get_text("å°±æ¥­å ´æ‰€")
                employment = get_text("é›‡ç”¨å½¢æ…‹")
                salary = get_text("è³ƒé‡‘")
                salary_type = get_text("è³ƒé‡‘å½¢æ…‹")
                work_time = get_text("å°±æ¥­æ™‚é–“")
                holiday = get_text("ä¼‘æ—¥ç­‰")
                qualification = get_text("å¿…è¦ãªå…è¨±ãƒ»è³‡æ ¼")
                experience = get_text("å¿…è¦ãªçµŒé¨“ç­‰")
                welfare = get_text("åŠ å…¥ä¿é™ºç­‰")
                notes = get_text("å‚™è€ƒ")

                # çµ¦ä¸æ•°å€¤æŠ½å‡º
                salary_nums = re.findall(r"\d{3,5}", salary.replace(",", ""))
                salary_min = salary_nums[0] if len(salary_nums) >= 1 else ""
                salary_max = salary_nums[1] if len(salary_nums) >= 2 else salary_min

                # æ¦‚è¦ç”Ÿæˆ
                job_summary = generate_summary(work_desc, salary_min, salary_max, location, work_time, welfare, holiday, notes, job_title)

                # ãŠã™ã™ã‚ãƒã‚¤ãƒ³ãƒˆæŠ½å‡º
                recommendations = extract_recommendations(salary_min, welfare, notes, work_desc, location)

                with st.expander(f"ğŸ“„ æ±‚äºº {i}: {job_title}", expanded=False):
                    col1, col2 = st.columns(2)

                    with col1:
                        st.subheader("ğŸ—‚ï¸ æ±‚äººæŠ½å‡ºæƒ…å ±")
                        st.markdown(f"""
                        **æ±‚äººã‚¿ã‚¤ãƒˆãƒ«**: {job_title}  
                        **ä¼šç¤¾å**: {company}  
                        **ä»•äº‹å†…å®¹**: {work_desc}  
                        **å°±æ¥­å ´æ‰€**: {location}  
                        **é›‡ç”¨å½¢æ…‹**: {employment}  
                        **çµ¦ä¸**: {salary}  
                        **è³ƒé‡‘å½¢æ…‹**: {salary_type}  
                        **çµ¦ä¸ä¸‹é™**: {salary_min}  
                        **çµ¦ä¸ä¸Šé™**: {salary_max}  
                        **å‹¤å‹™æ™‚é–“**: {work_time}  
                        **ä¼‘æ—¥ãƒ»ä¼‘æš‡**: {holiday}  
                        **å¿…é ˆè³‡æ ¼**: {qualification}  
                        **çµŒé¨“è¦å¦**: {experience}  
                        **ç¦åˆ©åšç”Ÿ**: {welfare}  
                        **å‚™è€ƒ**: {notes}  
                        """)

                    with col2:
                        st.subheader("âœ¨ æ±‚äººæ¦‚è¦")
                        st.markdown(job_summary)

                        st.subheader("ğŸ¯ ãŠã™ã™ã‚ãƒã‚¤ãƒ³ãƒˆ")
                        if recommendations:
                            st.markdown("ã€ãŠã™ã™ã‚ãƒã‚¤ãƒ³ãƒˆã€‘ " + " ".join([f"â– {r}" for r in recommendations]))
                        else:
                            st.markdown("ã€ãŠã™ã™ã‚ãƒã‚¤ãƒ³ãƒˆã€‘ è©²å½“æƒ…å ±ãªã—")

            except Exception as e:
                st.error(f"æ±‚äºº {i} ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
